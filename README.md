Multi Modal RAG (Retrieval-Augmented Generation) is an AI system that combines text, images,
and documents with retrieval and large language models to generate accurate, context-aware
responses.
Project Objective
• Combine multiple data modalities
• Retrieve relevant context
• Generate grounded AI responses
Key Features
• Text-based RAG
• Image-aware retrieval
• LLM-powered generation
• Vector search
Tech Stack
Python, LLMs, Vector Databases, Embeddings, Flask/FastAPI, LangChain
How It Works
1. User submits query
2. Embeddings are generated
3. Relevant context is retrieved
4. LLM generates response
Use Cases
• Document search
• Knowledge chatbots
• Image + text QA
License
MIT License
Author
JONCY KEDA
